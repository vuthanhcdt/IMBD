{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCecC5Y4WnCW"
      },
      "source": [
        "安裝python3.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyUsab0STQQq"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbI04oibXIm3"
      },
      "source": [
        "替換python版本"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VliDJsJfTScv"
      },
      "outputs": [],
      "source": [
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 3\n",
        "!python --version\n",
        "!sudo apt-get install python3.6-distutils\n",
        "!wget https://bootstrap.pypa.io/pip/3.6/get-pip.py\n",
        "!python get-pip.py\n",
        "# upgrade pip\n",
        "!sudo apt install python3-pip\n",
        "!python -m pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwlAnC8mKKWt"
      },
      "source": [
        "修正Tersonflow與Keras版本"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oryu7yWhF3in"
      },
      "outputs": [],
      "source": [
        "!pip uninstall keras\n",
        "!pip install tensorflow==2.2.0\n",
        "!pip install Keras==2.3.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baWEgaKBG4h3"
      },
      "source": [
        "匯入雲端硬碟"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VDsM0gWG8uQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/My\\ Drive/Colab\\ Notebooks/imbd2019\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/imbd2019/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CxJ6ifbG-k7"
      },
      "source": [
        "載入配置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3Q3J6j2HEHY"
      },
      "outputs": [],
      "source": [
        "class _config:\n",
        "    # train 資料夾位置\n",
        "    Train_Path = './train/'\n",
        "    # Train_Path = '/content/drive/My Drive/Colab Notebooks/imbd2019/train/'\n",
        "    # test 資料夾位置\n",
        "    Test_Path = './test/'\n",
        "    # Test_Path = '/content/drive/My Drive/Colab Notebooks/imbd2019/test/'\n",
        "    # img size\n",
        "    imgrow = 164\n",
        "    imgcol = 4\n",
        "    # PTC 類別定義\n",
        "    PTC_class = {'G11': 0, 'G15': 1, 'G17': 2, 'G19': 3,\n",
        "                 'G32': 4, 'G34': 5, 'G48': 6, 'G49': 7}\n",
        "    test_y = {'1.txt': 'G11', '2.txt': 'G11',\n",
        "              '3.txt': 'G15', '4.txt': 'G15', '5.txt': 'G15', '6.txt': 'G15', '7.txt': 'G15', '8.txt': 'G15',\n",
        "              '9.txt': 'G17', '10.txt': 'G17',\n",
        "              '11.txt': 'G19', '12.txt': 'G19',\n",
        "              '13.txt': 'G32', '14.txt': 'G32', '15.txt': 'G32', '16.txt': 'G32', '17.txt': 'G32', '18.txt': 'G32',\n",
        "              '19.txt': 'G34', '20.txt': 'G34', '21.txt': 'G34', '22.txt': 'G34', '23.txt': 'G34', '24.txt': 'G34',\n",
        "              '25.txt': 'G48', '26.txt': 'G48', '27.txt': 'G48', '28.txt': 'G48', '29.txt': 'G48', '30.txt': 'G48',\n",
        "              '31.txt': 'G49', '32.txt': 'G49', '33.txt': 'G49', '34.txt': 'G49', '35.txt': 'G49', '36.txt': 'G49',\n",
        "              }\n",
        "    Batch_size = 32\n",
        "    epoch = 70\n",
        "    class_num = 8\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00Dfo0MCHN_R"
      },
      "source": [
        "載入檔案"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fTIAW29pHfd8"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from os import walk\n",
        "import numpy as np\n",
        "import cv2\n",
        "#from config import _config\n",
        "\n",
        "class _file:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.Set = _config()\n",
        "        pass\n",
        "\n",
        "    def ReadData_TxT(self, Path):\n",
        "        AllPTCNp = np.zeros((1, self.Set.imgcol))\n",
        "        AllDataList = list()\n",
        "        labellsit = list()\n",
        "        PTClabelList = list()\n",
        "        namelist = list()\n",
        "        # 讀取資料夾內檔案\n",
        "        for root, dirs, file_all in walk(Path):\n",
        "\n",
        "            for _file in dirs:\n",
        "                # 讀取各類別資料夾(G11、G15、G17、G19、G32、G34、G48、G49)\n",
        "                for root, dirs, file_all in walk(Path+_file):\n",
        "                    # 讀取各類別資料夾內的TXT\n",
        "                    for name in file_all:\n",
        "                        # print(name)\n",
        "                        namelist.append(name)\n",
        "                        Datalist = list()\n",
        "                        SingleTxTNp = np.zeros((1, 4))\n",
        "                        PTCList = list()\n",
        "                        StartSaveData = False\n",
        "\n",
        "                        # 讀取TXT\n",
        "                        f = open(Path+_file+'/'+name, 'r', encoding='big5')\n",
        "                        data = f.readlines()\n",
        "                        for i in data:\n",
        "                            Datalist.append(i)\n",
        "                        f.close()\n",
        "\n",
        "                        # 讀取TXT內容後，淨化資料內容\n",
        "                        for i in Datalist:\n",
        "                            # 判斷此TXT類別\n",
        "                            if i.find('G') > -1:\n",
        "                                label = i[i.find('G'):i.find('-')]\n",
        "\n",
        "                                labellsit.append(label)\n",
        "                            # 經過Deg.F 確認開始讀取 PTC\n",
        "                            if StartSaveData:\n",
        "                                PTCList.append(i)\n",
        "\n",
        "                                # 若讀到換行符號，row方向往下堆疊\n",
        "                                if i.find('\\n') >= 0:\n",
        "                                    PTCList = PTCList[0].split('\\t')\n",
        "                                    showNp = np.array(PTCList)\n",
        "\n",
        "                                    PTCList = []\n",
        "                                    if showNp.shape[0] > 1:  # txt開頭有換行符號則須避開\n",
        "                                        SingleTxTNp = np.vstack(\n",
        "                                            (SingleTxTNp, showNp[0:self.Set.imgcol]))  # 資料往下堆疊\n",
        "                            if i.find('Deg.F') > -1:  # 經過Deg.F 確認開始讀取 PTC\n",
        "                                StartSaveData = True\n",
        "\n",
        "                        # 去除SingleTxTNp row=0資料，只留實際PTC資料\n",
        "                        SingleTxTNp = SingleTxTNp[1:self.Set.imgrow, :]\n",
        "                        SingleTxTNp_float = SingleTxTNp.astype(\n",
        "                            np.float)  # convert string array to float\n",
        "\n",
        "                        AllPTCNp = np.vstack(\n",
        "                            (AllPTCNp, SingleTxTNp_float))  # 讀完整個txt內容後存入結果\n",
        "                # 去除AllPTCNp row=0資料，只留實際PTC資料\n",
        "                ResultNp = AllPTCNp[1:AllPTCNp.shape[0], :].copy()\n",
        "\n",
        "        # 儲存Label資料\n",
        "        for i in labellsit:\n",
        "            i = i.strip(' ')\n",
        "            PTClabelList.append(self.Set.PTC_class[i])\n",
        "        PTClabelNp = np.array([PTClabelList])\n",
        "        PTClabelNp = PTClabelNp.T\n",
        "        print(ResultNp.shape)\n",
        "\n",
        "        return ResultNp, PTClabelNp, namelist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPLkLMh5Hhpt"
      },
      "source": [
        "資料前處理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BJJzNc2iHqdj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class _preprocess:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def splitdata(self, dataNp, ratio, imgrow):\n",
        "        # input資料row維度\n",
        "        imgcounter = int(dataNp.shape[0]/imgrow)\n",
        "        # train維度=all*ratio\n",
        "        trainCounter = int(imgcounter*ratio)\n",
        "        trainNp = dataNp[0:trainCounter*imgrow, :]\n",
        "\n",
        "        # test=all-train\n",
        "        testNp = dataNp[trainCounter*imgrow:imgcounter*imgrow, :]\n",
        "\n",
        "        return trainNp, testNp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0MmsErwHtTf"
      },
      "source": [
        "訓練模型配置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rBBdoDHDHx9_"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import sys\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Activation, Bidirectional\n",
        "#from tensorflow.keras.optimizers import Adam\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import LSTM\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Conv1D, MaxPooling1D, GlobalAveragePooling1D, MaxPool2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adadelta\n",
        "#from preprocess import _preprocess\n",
        "#from config import _config\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import pickle\n",
        "import gzip\n",
        "import urllib.request\n",
        "import json\n",
        "\n",
        "def plothistory(history):\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "# 繪製訓練 & 驗證的損失值\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "class CNN_Model:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        pass\n",
        "\n",
        "    def Classification(self, x_train_all_Np, y_train_all_Np, x_testNp, y_testNp):\n",
        "        Set = _config()\n",
        "        process = _preprocess()\n",
        "\n",
        "        # train data分80%,test data分20%\n",
        "        train_x_np, val_x_np = process.splitdata(x_train_all_Np, 0.8, 1)\n",
        "        train_y_np, val_y_np = process.splitdata(y_train_all_Np, 0.8, 1)\n",
        "        print(train_x_np.shape, val_x_np.shape,\n",
        "              train_y_np.shape, val_y_np.shape)\n",
        "\n",
        "        # input image dimensions\n",
        "        img_rows, img_cols = Set.imgrow-1, Set.imgcol\n",
        "        train_x_np = train_x_np.reshape(\n",
        "            int(train_x_np.shape[0]/(img_rows)), img_rows, img_cols, 1)\n",
        "        val_x_np = val_x_np.reshape(\n",
        "            int(val_x_np.shape[0]/(img_rows)), img_rows, img_cols, 1)\n",
        "        x_train_all_Np = x_train_all_Np.reshape(\n",
        "            int(x_train_all_Np.shape[0]/(img_rows)), img_rows, img_cols, 1)\n",
        "        # print(x_train_all_Np.shape,x_testNp.shape)\n",
        "\n",
        "        _input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "        # Normalize\n",
        "        x_mean = np.mean(x_train_all_Np, axis=0)\n",
        "        x_std = np.std(x_train_all_Np, axis=0)\n",
        "\n",
        "        train_x_np = (train_x_np-x_mean)/x_std\n",
        "        val_x_np = (val_x_np-x_mean)/x_std\n",
        "\n",
        "        print('x_train shape:', x_train_all_Np.shape)\n",
        "        print(train_x_np.shape, 'train samples')\n",
        "        print(val_x_np.shape, 'val samples')\n",
        "        print(train_y_np.shape, 'trainy samples')\n",
        "        print(val_y_np.shape, 'valy samples')\n",
        "        print(train_y_np)\n",
        "        train_y_np_Onehot = keras.utils.to_categorical(\n",
        "            train_y_np, Set.class_num)\n",
        "        val_y_np_Onehot = keras.utils.to_categorical(val_y_np, Set.class_num)\n",
        "        print('train_y_np_Onehot', train_y_np_Onehot.shape,\n",
        "              'val_y_np_Onehot', val_y_np_Onehot.shape)\n",
        "\n",
        "        print('_input_shape', _input_shape)\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(64, kernel_size=(1, 1),\n",
        "                         activation='relu',\n",
        "                         #  padding='SAME',\n",
        "                         input_shape=_input_shape))\n",
        "        # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "        # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Conv2D(64, kernel_size=(1, 1), activation='relu'))\n",
        "        # # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "        # # model.add(Conv2D(64, kernel_size=(2, 2),activation='relu'))#\n",
        "\n",
        "        # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "\n",
        "        # model.add(Conv2D(64, kernel_size=(1, 1),activation='relu'))#\n",
        "\n",
        "        # model.add(MaxPooling2D(pool_size=(2, 2)))#\n",
        "\n",
        "        # model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "        # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        # model.add(Dropout(0.25))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dense(256, activation='relu'))\n",
        "        # model.add(Dense(512, activation='relu'))\n",
        "        model.add(Dense(512, activation='relu'))\n",
        "        # model.add(Dense(1024, activation='relu'))\n",
        "        model.add(Dense(1024, activation='relu'))\n",
        "        model.add(Dense(2048, activation='relu'))\n",
        "        # model.add(Dense(2048, activation='relu'))\n",
        "        # model.add(Dense(2048, activation='relu'))\n",
        "        # model.add(Dense(1024, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(Set.class_num, activation='softmax'))\n",
        "\n",
        "        model.summary()\n",
        "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                      optimizer='adam',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        # model.fit(x_train_all_Np, y_train_all_Np_Onehot, validation_split=0.2, batch_size=32, epochs=50)\n",
        "        print('t', val_x_np.shape, val_y_np_Onehot.shape)\n",
        "\n",
        "        history = model.fit(train_x_np,\n",
        "                            train_y_np_Onehot,\n",
        "                            # validation_split=0.5,\n",
        "                            batch_size=Set.Batch_size,\n",
        "                            epochs=Set.epoch,\n",
        "                            # verbose=1)\n",
        "                            validation_data=(val_x_np, val_y_np_Onehot))\n",
        "        # score = model.evaluate(x_testNp, y_testNp_Onehot)\n",
        "        score = model.evaluate(val_x_np, val_y_np_Onehot, verbose=0)\n",
        "\n",
        "        x_testNp = x_testNp.reshape(\n",
        "            int(x_testNp.shape[0]/(img_rows)), img_rows, img_cols, 1)\n",
        "        x_testNp = (x_testNp-x_mean)/x_std\n",
        "\n",
        "        #predction = model.predict_classes(x_testNp)\n",
        "        predict_x=model.predict(x_testNp)\n",
        "        predction=np.argmax(predict_x,axis=1)\n",
        "        # print(predction)\n",
        "        print('Test loss:', score[0])\n",
        "        print('Test accuracy:', score[1])\n",
        "        # plothistory(history)\n",
        "\n",
        "        return predction\n",
        "\n",
        "\n",
        "class LSTM_Model:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def Classification(self, x_train_all_Np, y_train_all_Np, x_testNp, y_testNp):\n",
        "        Set = _config()\n",
        "        process = _preprocess()\n",
        "        # learning_rate = 0.001\n",
        "        training_iters = Set.epoch\n",
        "        batch_size = Set.Batch_size\n",
        "        display_step = 10\n",
        "\n",
        "        n_input = Set.imgcol\n",
        "        n_step = Set.imgrow-1\n",
        "        n_hidden = 256\n",
        "        n_classes = Set.class_num\n",
        "\n",
        "        train_x_np, val_x_np = process.splitdata(x_train_all_Np, 0.8, 1)\n",
        "        train_y_np, val_y_np = process.splitdata(y_train_all_Np, 0.8, 1)\n",
        "\n",
        "        x_train_all_Np = x_train_all_Np.reshape(-1, n_step, n_input)\n",
        "        train_x_np = train_x_np.reshape(-1, n_step, n_input)\n",
        "        val_x_np = val_x_np.reshape(-1, n_step, n_input)\n",
        "\n",
        "        # train_x_np = train_x_np.astype('float32')\n",
        "        # val_x_np = val_x_np.astype('float32')\n",
        "\n",
        "        x_mean = np.mean(x_train_all_Np, axis=0)\n",
        "        x_std = np.std(x_train_all_Np, axis=0)\n",
        "\n",
        "        train_x_np = (train_x_np-x_mean)/x_std\n",
        "        val_x_np = (val_x_np-x_mean)/x_std\n",
        "\n",
        "        train_y_np_Onehot = keras.utils.to_categorical(train_y_np, n_classes)\n",
        "        val_y_np_Onehot = keras.utils.to_categorical(val_y_np, n_classes)\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(n_hidden, batch_input_shape=(\n",
        "            None, n_step, n_input), unroll=True))\n",
        "        # model.add(LSTM(n_hidden,unroll=True))\n",
        "        # model.add(LSTM(n_hidden))\n",
        "\n",
        "        # model.add(LSTM(n_hidden,batch_input_shape=(None, n_step, n_input),unroll=True))\n",
        "\n",
        "        # model.add(Bidirectional(LSTM(units=2,return_sequences=False)))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(n_classes))\n",
        "        model.add(Activation('softmax'))\n",
        "\n",
        "        adam = Adam(lr=0.001)\n",
        "        model.summary()\n",
        "        model.compile(optimizer=adam,\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        model.fit(train_x_np, train_y_np_Onehot,\n",
        "                  batch_size=batch_size,\n",
        "                  epochs=training_iters,\n",
        "                  verbose=1,\n",
        "                  validation_data=(val_x_np, val_y_np_Onehot))\n",
        "\n",
        "        scores = model.evaluate(val_x_np, val_y_np_Onehot, verbose=2)\n",
        "        print('LSTM test score:', scores[0])\n",
        "        print('LSTM test accuracy:', scores[1])\n",
        "\n",
        "        x_testNp = x_testNp.reshape(-1, n_step, n_input)\n",
        "        x_testNp = (x_testNp-x_mean)/x_std\n",
        "        predction = model.predict_classes(x_testNp)\n",
        "        print(predction)\n",
        "        return predction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emh3ngEcH4ou"
      },
      "source": [
        "主程式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRYs1oheH-wm",
        "outputId": "ceb8b099-aca0-42ea-dc6e-cda19c6cca6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-82a591908501>:67: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  np.float)  # convert string array to float\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(37490, 4)\n",
            "(5868, 4)\n",
            "======= (37490, 4) (230, 1)\n",
            "(29992, 4) (7498, 4) (184, 1) (46, 1)\n",
            "x_train shape: (230, 163, 4, 1)\n",
            "(184, 163, 4, 1) train samples\n",
            "(46, 163, 4, 1) val samples\n",
            "(184, 1) trainy samples\n",
            "(46, 1) valy samples\n",
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [2]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [5]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [6]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [3]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]\n",
            " [4]]\n",
            "train_y_np_Onehot (184, 8) val_y_np_Onehot (46, 8)\n",
            "_input_shape (163, 4, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 163, 4, 64)        128       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 81, 2, 64)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 81, 2, 64)         4160      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 40, 1, 64)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2560)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               327808    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2048)              2099200   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 8)                 16392     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,137,608\n",
            "Trainable params: 3,137,608\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "t (46, 163, 4, 1) (46, 8)\n",
            "Epoch 1/70\n",
            "6/6 [==============================] - 3s 180ms/step - loss: 1.7047 - accuracy: 0.3641 - val_loss: 4.4885 - val_accuracy: 0.2609\n",
            "Epoch 2/70\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.9627 - accuracy: 0.4891 - val_loss: 6.3901 - val_accuracy: 0.2609\n",
            "Epoch 3/70\n",
            "6/6 [==============================] - 1s 121ms/step - loss: 0.9057 - accuracy: 0.5652 - val_loss: 5.8155 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/70\n",
            "6/6 [==============================] - 1s 127ms/step - loss: 0.6867 - accuracy: 0.6902 - val_loss: 6.7538 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/70\n",
            "6/6 [==============================] - 1s 131ms/step - loss: 0.5844 - accuracy: 0.6848 - val_loss: 9.8467 - val_accuracy: 0.2609\n",
            "Epoch 6/70\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 0.4819 - accuracy: 0.7391 - val_loss: 10.3775 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/70\n",
            "6/6 [==============================] - 1s 133ms/step - loss: 0.4022 - accuracy: 0.7989 - val_loss: 10.4401 - val_accuracy: 0.2609\n",
            "Epoch 8/70\n",
            "6/6 [==============================] - 1s 141ms/step - loss: 0.3604 - accuracy: 0.8315 - val_loss: 9.8022 - val_accuracy: 0.2609\n",
            "Epoch 9/70\n",
            "6/6 [==============================] - 1s 131ms/step - loss: 0.2850 - accuracy: 0.8533 - val_loss: 11.5393 - val_accuracy: 0.2609\n",
            "Epoch 10/70\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.2235 - accuracy: 0.8750 - val_loss: 11.2832 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/70\n",
            "6/6 [==============================] - 1s 139ms/step - loss: 0.1867 - accuracy: 0.8859 - val_loss: 11.9895 - val_accuracy: 0.2609\n",
            "Epoch 12/70\n",
            "6/6 [==============================] - 1s 142ms/step - loss: 0.1648 - accuracy: 0.9348 - val_loss: 12.4863 - val_accuracy: 0.1739\n",
            "Epoch 13/70\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.1786 - accuracy: 0.8859 - val_loss: 13.0877 - val_accuracy: 0.1522\n",
            "Epoch 14/70\n",
            "6/6 [==============================] - 1s 121ms/step - loss: 0.2045 - accuracy: 0.8696 - val_loss: 13.7151 - val_accuracy: 0.2609\n",
            "Epoch 15/70\n",
            "6/6 [==============================] - 0s 81ms/step - loss: 0.1675 - accuracy: 0.9076 - val_loss: 14.0747 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/70\n",
            "6/6 [==============================] - 0s 81ms/step - loss: 0.1688 - accuracy: 0.8913 - val_loss: 15.2040 - val_accuracy: 0.0652\n",
            "Epoch 17/70\n",
            "6/6 [==============================] - 0s 83ms/step - loss: 0.1570 - accuracy: 0.9239 - val_loss: 15.8652 - val_accuracy: 0.2609\n",
            "Epoch 18/70\n",
            "6/6 [==============================] - 1s 91ms/step - loss: 0.1463 - accuracy: 0.9239 - val_loss: 17.5044 - val_accuracy: 0.2391\n",
            "Epoch 19/70\n",
            "6/6 [==============================] - 0s 84ms/step - loss: 0.1273 - accuracy: 0.9457 - val_loss: 16.9473 - val_accuracy: 0.1739\n",
            "Epoch 20/70\n",
            "6/6 [==============================] - 0s 79ms/step - loss: 0.1417 - accuracy: 0.9457 - val_loss: 17.5353 - val_accuracy: 0.2391\n",
            "Epoch 21/70\n",
            "6/6 [==============================] - 1s 87ms/step - loss: 0.1351 - accuracy: 0.9402 - val_loss: 16.9488 - val_accuracy: 0.1739\n",
            "Epoch 22/70\n",
            "6/6 [==============================] - 0s 82ms/step - loss: 0.1230 - accuracy: 0.9457 - val_loss: 17.4816 - val_accuracy: 0.1304\n",
            "Epoch 23/70\n",
            "6/6 [==============================] - 0s 80ms/step - loss: 0.1252 - accuracy: 0.9402 - val_loss: 20.6442 - val_accuracy: 0.2391\n",
            "Epoch 24/70\n",
            "6/6 [==============================] - 0s 78ms/step - loss: 0.0911 - accuracy: 0.9565 - val_loss: 22.0591 - val_accuracy: 0.1957\n",
            "Epoch 25/70\n",
            "6/6 [==============================] - 0s 78ms/step - loss: 0.0769 - accuracy: 0.9565 - val_loss: 24.1329 - val_accuracy: 0.2609\n",
            "Epoch 26/70\n",
            "6/6 [==============================] - 0s 83ms/step - loss: 0.0940 - accuracy: 0.9565 - val_loss: 24.3638 - val_accuracy: 0.2391\n",
            "Epoch 27/70\n",
            "6/6 [==============================] - 0s 82ms/step - loss: 0.0460 - accuracy: 0.9946 - val_loss: 24.7410 - val_accuracy: 0.1739\n",
            "Epoch 28/70\n",
            "6/6 [==============================] - 0s 84ms/step - loss: 0.0352 - accuracy: 0.9837 - val_loss: 28.1118 - val_accuracy: 0.2609\n",
            "Epoch 29/70\n",
            "6/6 [==============================] - 0s 80ms/step - loss: 0.0816 - accuracy: 0.9837 - val_loss: 26.0202 - val_accuracy: 0.1739\n",
            "Epoch 30/70\n",
            "6/6 [==============================] - 0s 81ms/step - loss: 0.1066 - accuracy: 0.9565 - val_loss: 23.9803 - val_accuracy: 0.1739\n",
            "Epoch 31/70\n",
            "6/6 [==============================] - 0s 80ms/step - loss: 0.1011 - accuracy: 0.9511 - val_loss: 23.2208 - val_accuracy: 0.1087\n",
            "Epoch 32/70\n",
            "6/6 [==============================] - 0s 83ms/step - loss: 0.0831 - accuracy: 0.9674 - val_loss: 27.9683 - val_accuracy: 0.2174\n",
            "Epoch 33/70\n",
            "6/6 [==============================] - 0s 85ms/step - loss: 0.0749 - accuracy: 0.9674 - val_loss: 34.3597 - val_accuracy: 0.2174\n",
            "Epoch 34/70\n",
            "6/6 [==============================] - 1s 87ms/step - loss: 0.0760 - accuracy: 0.9620 - val_loss: 34.4150 - val_accuracy: 0.2174\n",
            "Epoch 35/70\n",
            "6/6 [==============================] - 1s 138ms/step - loss: 0.0882 - accuracy: 0.9620 - val_loss: 30.6720 - val_accuracy: 0.1739\n",
            "Epoch 36/70\n",
            "6/6 [==============================] - 1s 129ms/step - loss: 0.1235 - accuracy: 0.9239 - val_loss: 31.4677 - val_accuracy: 0.2391\n",
            "Epoch 37/70\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 0.7138 - accuracy: 0.9511 - val_loss: 26.7754 - val_accuracy: 0.1957\n",
            "Epoch 38/70\n",
            "6/6 [==============================] - 1s 144ms/step - loss: 0.8695 - accuracy: 0.8207 - val_loss: 10.2268 - val_accuracy: 0.1739\n",
            "Epoch 39/70\n",
            "6/6 [==============================] - 1s 142ms/step - loss: 0.3199 - accuracy: 0.9293 - val_loss: 9.7442 - val_accuracy: 0.2174\n",
            "Epoch 40/70\n",
            "6/6 [==============================] - 1s 146ms/step - loss: 0.0958 - accuracy: 1.0000 - val_loss: 23.2255 - val_accuracy: 0.2609\n",
            "Epoch 41/70\n",
            "6/6 [==============================] - 1s 140ms/step - loss: 0.4187 - accuracy: 0.9130 - val_loss: 21.8497 - val_accuracy: 0.0870\n",
            "Epoch 42/70\n",
            "6/6 [==============================] - 1s 141ms/step - loss: 0.1482 - accuracy: 0.9457 - val_loss: 23.8841 - val_accuracy: 0.2391\n",
            "Epoch 43/70\n",
            "6/6 [==============================] - 1s 145ms/step - loss: 0.1275 - accuracy: 0.9674 - val_loss: 21.5140 - val_accuracy: 0.1739\n",
            "Epoch 44/70\n",
            "6/6 [==============================] - 1s 133ms/step - loss: 0.1014 - accuracy: 0.9511 - val_loss: 22.8863 - val_accuracy: 0.1304\n",
            "Epoch 45/70\n",
            "6/6 [==============================] - 1s 144ms/step - loss: 0.0651 - accuracy: 0.9728 - val_loss: 30.3321 - val_accuracy: 0.2391\n",
            "Epoch 46/70\n",
            "6/6 [==============================] - 1s 130ms/step - loss: 0.0376 - accuracy: 0.9891 - val_loss: 36.2841 - val_accuracy: 0.2391\n",
            "Epoch 47/70\n",
            "6/6 [==============================] - 1s 124ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 39.6131 - val_accuracy: 0.2391\n",
            "Epoch 48/70\n",
            "6/6 [==============================] - 0s 81ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 38.7750 - val_accuracy: 0.2391\n",
            "Epoch 49/70\n",
            "6/6 [==============================] - 0s 82ms/step - loss: 0.0299 - accuracy: 0.9891 - val_loss: 37.8592 - val_accuracy: 0.2391\n",
            "Epoch 50/70\n",
            "6/6 [==============================] - 1s 87ms/step - loss: 0.0231 - accuracy: 0.9946 - val_loss: 36.7013 - val_accuracy: 0.1957\n",
            "Epoch 51/70\n",
            "6/6 [==============================] - 0s 82ms/step - loss: 0.0109 - accuracy: 0.9946 - val_loss: 38.4600 - val_accuracy: 0.2391\n",
            "Epoch 52/70\n",
            "6/6 [==============================] - 1s 116ms/step - loss: 0.0405 - accuracy: 0.9891 - val_loss: 35.1867 - val_accuracy: 0.1739\n",
            "Epoch 53/70\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 0.0590 - accuracy: 0.9783 - val_loss: 38.4984 - val_accuracy: 0.2391\n",
            "Epoch 54/70\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 0.0323 - accuracy: 0.9891 - val_loss: 36.0942 - val_accuracy: 0.2391\n",
            "Epoch 55/70\n",
            "6/6 [==============================] - 1s 96ms/step - loss: 0.0181 - accuracy: 0.9946 - val_loss: 35.4527 - val_accuracy: 0.2391\n",
            "Epoch 56/70\n",
            "6/6 [==============================] - 1s 170ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 37.8712 - val_accuracy: 0.2391\n",
            "Epoch 57/70\n",
            "6/6 [==============================] - 1s 85ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 37.2237 - val_accuracy: 0.2391\n",
            "Epoch 58/70\n",
            "6/6 [==============================] - 0s 81ms/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 38.3640 - val_accuracy: 0.2391\n",
            "Epoch 59/70\n",
            "6/6 [==============================] - 0s 82ms/step - loss: 0.0072 - accuracy: 0.9946 - val_loss: 37.7973 - val_accuracy: 0.2391\n",
            "Epoch 60/70\n",
            "6/6 [==============================] - 1s 85ms/step - loss: 0.0158 - accuracy: 0.9891 - val_loss: 38.4566 - val_accuracy: 0.2391\n",
            "Epoch 61/70\n",
            "6/6 [==============================] - 0s 81ms/step - loss: 0.0100 - accuracy: 0.9946 - val_loss: 37.7126 - val_accuracy: 0.2391\n",
            "Epoch 62/70\n",
            "6/6 [==============================] - 0s 84ms/step - loss: 0.0178 - accuracy: 0.9946 - val_loss: 36.0713 - val_accuracy: 0.2391\n",
            "Epoch 63/70\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 0.0130 - accuracy: 0.9946 - val_loss: 38.0453 - val_accuracy: 0.2391\n",
            "Epoch 64/70\n",
            "6/6 [==============================] - 1s 86ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 37.5758 - val_accuracy: 0.2391\n",
            "Epoch 65/70\n",
            "6/6 [==============================] - 1s 132ms/step - loss: 0.0066 - accuracy: 0.9946 - val_loss: 37.7343 - val_accuracy: 0.2391\n",
            "Epoch 66/70\n",
            "6/6 [==============================] - 1s 134ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 39.1013 - val_accuracy: 0.2391\n",
            "Epoch 67/70\n",
            "6/6 [==============================] - 1s 136ms/step - loss: 7.8283e-04 - accuracy: 1.0000 - val_loss: 39.7733 - val_accuracy: 0.2391\n",
            "Epoch 68/70\n",
            "6/6 [==============================] - 1s 133ms/step - loss: 4.2665e-04 - accuracy: 1.0000 - val_loss: 40.1723 - val_accuracy: 0.2391\n",
            "Epoch 69/70\n",
            "6/6 [==============================] - 1s 135ms/step - loss: 1.2150e-04 - accuracy: 1.0000 - val_loss: 40.6279 - val_accuracy: 0.2391\n",
            "Epoch 70/70\n",
            "6/6 [==============================] - 1s 134ms/step - loss: 1.4219e-04 - accuracy: 1.0000 - val_loss: 41.1969 - val_accuracy: 0.2391\n",
            "2/2 [==============================] - 0s 10ms/step\n",
            "Test loss: 41.19687271118164\n",
            "Test accuracy: 0.239130437374115\n",
            "predict: [0 3 2 5 0 3 4 4 5 4 4 4 5 0 5 5 5 6 6 4 1 6 1 6 6 1 1 4 6 6 6 6 6 1 1 2]\n",
            "Real:    [0 3 2 5 4 3 4 4 5 4 4 4 5 0 5 5 5 7 6 7 1 6 1 6 6 1 1 7 7 7 6 6 7 1 1 2]\n",
            "Accuracy(%): 80.55555555555556\n"
          ]
        }
      ],
      "source": [
        "#from file import _file\n",
        "#from config import _config\n",
        "#from Mymodel import CNN_Model, LSTM_Model\n",
        "import numpy as np\n",
        "#import tensorflow as tf\n",
        "from keras.backend import set_session\n",
        "from tkinter import font\n",
        "import os\n",
        "\n",
        "def Project_Classification():\n",
        "    tXt = _file()\n",
        "    Set = _config()\n",
        "    # 讀取train data 及 test data\n",
        "    train_x, train_y, trainfilename = tXt.ReadData_TxT(Set.Train_Path)\n",
        "    test_x, test_y, testfilename = tXt.ReadData_TxT(Set.Test_Path)\n",
        "    print('=======', train_x.shape, train_y.shape)\n",
        "    # print(testfilename)\n",
        "    Real_y = list()\n",
        "    for i in testfilename:\n",
        "        _class = Set.test_y[i]\n",
        "        Real_y.append(Set.PTC_class[_class])\n",
        "    CNN = CNN_Model()\n",
        "    Predict_Y = CNN.Classification(train_x, train_y, test_x, test_y)\n",
        "    # goolgenet=goolgenet_Model()\n",
        "    # goolgenet.Classification(train_x,train_y,test_x,test_y)\n",
        "    # LSTM=LSTM_Model()\n",
        "    # Predict_Y=LSTM.Classification(train_x,train_y,test_x,test_y)\n",
        "\n",
        "    Real_yNp = np.array(Real_y)\n",
        "    print('predict:', Predict_Y)\n",
        "    print('Real:   ', Real_yNp)\n",
        "    Result = 0\n",
        "    for i in range(Real_yNp.shape[0]):\n",
        "        if(Predict_Y[i] == Real_yNp[i]):\n",
        "            Result = Result+1\n",
        "    Error = Result/Real_yNp.shape[0]\n",
        "    print('Accuracy(%):', Error*100)\n",
        "\n",
        "\n",
        "def main():\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # 使用 GPU 0\n",
        "    Project_Classification()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
