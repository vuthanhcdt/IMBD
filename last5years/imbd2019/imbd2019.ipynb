{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCecC5Y4WnCW"
      },
      "source": [
        "安裝python3.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyUsab0STQQq"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbI04oibXIm3"
      },
      "source": [
        "替換python版本"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VliDJsJfTScv"
      },
      "outputs": [],
      "source": [
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 3\n",
        "!python --version\n",
        "!sudo apt-get install python3.6-distutils\n",
        "!wget https://bootstrap.pypa.io/pip/3.6/get-pip.py\n",
        "!python get-pip.py\n",
        "# upgrade pip\n",
        "!sudo apt install python3-pip\n",
        "!python -m pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwlAnC8mKKWt"
      },
      "source": [
        "修正Tersonflow與Keras版本"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oryu7yWhF3in"
      },
      "outputs": [],
      "source": [
        "!pip uninstall keras\n",
        "!pip install tensorflow==2.2.0\n",
        "!pip install Keras==2.3.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baWEgaKBG4h3"
      },
      "source": [
        "匯入雲端硬碟"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VDsM0gWG8uQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls /content/drive/My\\ Drive/Colab\\ Notebooks/imbd2019\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/imbd2019/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CxJ6ifbG-k7"
      },
      "source": [
        "載入配置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N3Q3J6j2HEHY"
      },
      "outputs": [],
      "source": [
        "class _config:\n",
        "    # train 資料夾位置\n",
        "    Train_Path = './train/'\n",
        "    # Train_Path = '/content/drive/My Drive/Colab Notebooks/imbd2019/train/'\n",
        "    # test 資料夾位置\n",
        "    Test_Path = './test/'\n",
        "    # Test_Path = '/content/drive/My Drive/Colab Notebooks/imbd2019/test/'\n",
        "    # img size\n",
        "    imgrow = 164\n",
        "    imgcol = 4\n",
        "    # PTC 類別定義\n",
        "    PTC_class = {'G11': 0, 'G15': 1, 'G17': 2, 'G19': 3,\n",
        "                 'G32': 4, 'G34': 5, 'G48': 6, 'G49': 7}\n",
        "    test_y = {'1.txt': 'G11', '2.txt': 'G11',\n",
        "              '3.txt': 'G15', '4.txt': 'G15', '5.txt': 'G15', '6.txt': 'G15', '7.txt': 'G15', '8.txt': 'G15',\n",
        "              '9.txt': 'G17', '10.txt': 'G17',\n",
        "              '11.txt': 'G19', '12.txt': 'G19',\n",
        "              '13.txt': 'G32', '14.txt': 'G32', '15.txt': 'G32', '16.txt': 'G32', '17.txt': 'G32', '18.txt': 'G32',\n",
        "              '19.txt': 'G34', '20.txt': 'G34', '21.txt': 'G34', '22.txt': 'G34', '23.txt': 'G34', '24.txt': 'G34',\n",
        "              '25.txt': 'G48', '26.txt': 'G48', '27.txt': 'G48', '28.txt': 'G48', '29.txt': 'G48', '30.txt': 'G48',\n",
        "              '31.txt': 'G49', '32.txt': 'G49', '33.txt': 'G49', '34.txt': 'G49', '35.txt': 'G49', '36.txt': 'G49',\n",
        "              }\n",
        "    Batch_size = 32\n",
        "    epoch = 70\n",
        "    class_num = 8\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00Dfo0MCHN_R"
      },
      "source": [
        "載入檔案"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fTIAW29pHfd8"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from os import walk\n",
        "import numpy as np\n",
        "import cv2\n",
        "#from config import _config\n",
        "\n",
        "class _file:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.Set = _config()\n",
        "        pass\n",
        "\n",
        "    def ReadData_TxT(self, Path):\n",
        "        AllPTCNp = np.zeros((1, self.Set.imgcol))\n",
        "        AllDataList = list()\n",
        "        labellsit = list()\n",
        "        PTClabelList = list()\n",
        "        namelist = list()\n",
        "        # 讀取資料夾內檔案\n",
        "        for root, dirs, file_all in walk(Path):\n",
        "\n",
        "            for _file in dirs:\n",
        "                # 讀取各類別資料夾(G11、G15、G17、G19、G32、G34、G48、G49)\n",
        "                for root, dirs, file_all in walk(Path+_file):\n",
        "                    # 讀取各類別資料夾內的TXT\n",
        "                    for name in file_all:\n",
        "                        # print(name)\n",
        "                        namelist.append(name)\n",
        "                        Datalist = list()\n",
        "                        SingleTxTNp = np.zeros((1, 4))\n",
        "                        PTCList = list()\n",
        "                        StartSaveData = False\n",
        "\n",
        "                        # 讀取TXT\n",
        "                        f = open(Path+_file+'/'+name, 'r', encoding='big5')\n",
        "                        data = f.readlines()\n",
        "                        for i in data:\n",
        "                            Datalist.append(i)\n",
        "                        f.close()\n",
        "\n",
        "                        # 讀取TXT內容後，淨化資料內容\n",
        "                        for i in Datalist:\n",
        "                            # 判斷此TXT類別\n",
        "                            if i.find('G') > -1:\n",
        "                                label = i[i.find('G'):i.find('-')]\n",
        "\n",
        "                                labellsit.append(label)\n",
        "                            # 經過Deg.F 確認開始讀取 PTC\n",
        "                            if StartSaveData:\n",
        "                                PTCList.append(i)\n",
        "\n",
        "                                # 若讀到換行符號，row方向往下堆疊\n",
        "                                if i.find('\\n') >= 0:\n",
        "                                    PTCList = PTCList[0].split('\\t')\n",
        "                                    showNp = np.array(PTCList)\n",
        "\n",
        "                                    PTCList = []\n",
        "                                    if showNp.shape[0] > 1:  # txt開頭有換行符號則須避開\n",
        "                                        SingleTxTNp = np.vstack(\n",
        "                                            (SingleTxTNp, showNp[0:self.Set.imgcol]))  # 資料往下堆疊\n",
        "                            if i.find('Deg.F') > -1:  # 經過Deg.F 確認開始讀取 PTC\n",
        "                                StartSaveData = True\n",
        "\n",
        "                        # 去除SingleTxTNp row=0資料，只留實際PTC資料\n",
        "                        SingleTxTNp = SingleTxTNp[1:self.Set.imgrow, :]\n",
        "                        SingleTxTNp_float = SingleTxTNp.astype(\n",
        "                            np.float)  # convert string array to float\n",
        "\n",
        "                        AllPTCNp = np.vstack(\n",
        "                            (AllPTCNp, SingleTxTNp_float))  # 讀完整個txt內容後存入結果\n",
        "                # 去除AllPTCNp row=0資料，只留實際PTC資料\n",
        "                ResultNp = AllPTCNp[1:AllPTCNp.shape[0], :].copy()\n",
        "\n",
        "        # 儲存Label資料\n",
        "        for i in labellsit:\n",
        "            i = i.strip(' ')\n",
        "            PTClabelList.append(self.Set.PTC_class[i])\n",
        "        PTClabelNp = np.array([PTClabelList])\n",
        "        PTClabelNp = PTClabelNp.T\n",
        "        print(ResultNp.shape)\n",
        "\n",
        "        return ResultNp, PTClabelNp, namelist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPLkLMh5Hhpt"
      },
      "source": [
        "資料前處理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BJJzNc2iHqdj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class _preprocess:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def splitdata(self, dataNp, ratio, imgrow):\n",
        "        # input資料row維度\n",
        "        imgcounter = int(dataNp.shape[0]/imgrow)\n",
        "        # train維度=all*ratio\n",
        "        trainCounter = int(imgcounter*ratio)\n",
        "        trainNp = dataNp[0:trainCounter*imgrow, :]\n",
        "\n",
        "        # test=all-train\n",
        "        testNp = dataNp[trainCounter*imgrow:imgcounter*imgrow, :]\n",
        "\n",
        "        return trainNp, testNp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0MmsErwHtTf"
      },
      "source": [
        "訓練模型配置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rBBdoDHDHx9_"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import sys\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Activation, Bidirectional, LSTM, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "import pickle\n",
        "import gzip\n",
        "import urllib.request\n",
        "import json\n",
        "\n",
        "def plothistory(history):\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "class CNN_Model:\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def Classification(self, x_train_all_Np, y_train_all_Np, x_testNp, y_testNp):\n",
        "        # Assuming _config and _preprocess are defined somewhere in your code\n",
        "        Set = _config()\n",
        "        process = _preprocess()\n",
        "\n",
        "        train_x_np, val_x_np = process.splitdata(x_train_all_Np, 0.8, 1)\n",
        "        train_y_np, val_y_np = process.splitdata(y_train_all_Np, 0.8, 1)\n",
        "\n",
        "        img_rows, img_cols = Set.imgrow-1, Set.imgcol\n",
        "        train_x_np = train_x_np.reshape(int(train_x_np.shape[0]/(img_rows)), img_rows, img_cols, 1)\n",
        "        val_x_np = val_x_np.reshape(int(val_x_np.shape[0]/(img_rows)), img_rows, img_cols, 1)\n",
        "        x_train_all_Np = x_train_all_Np.reshape(int(x_train_all_Np.shape[0]/(img_rows)), img_rows, img_cols, 1)\n",
        "\n",
        "        _input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "        x_mean = np.mean(x_train_all_Np, axis=0)\n",
        "        x_std = np.std(x_train_all_Np, axis=0)\n",
        "\n",
        "        train_x_np = (train_x_np-x_mean)/x_std\n",
        "        val_x_np = (val_x_np-x_mean)/x_std\n",
        "\n",
        "        train_y_np_Onehot = to_categorical(train_y_np, Set.class_num)\n",
        "        val_y_np_Onehot = to_categorical(val_y_np, Set.class_num)\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(64, kernel_size=(1, 1), activation='relu', input_shape=_input_shape))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Conv2D(64, kernel_size=(1, 1), activation='relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, activation='relu'))\n",
        "        model.add(Dense(256, activation='relu'))\n",
        "        model.add(Dense(512, activation='relu'))\n",
        "        model.add(Dense(1024, activation='relu'))\n",
        "        model.add(Dense(2048, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(Set.class_num, activation='softmax'))\n",
        "\n",
        "        model.summary()\n",
        "        model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "        history = model.fit(train_x_np, train_y_np_Onehot, batch_size=Set.Batch_size, epochs=Set.epoch, validation_data=(val_x_np, val_y_np_Onehot))\n",
        "        score = model.evaluate(val_x_np, val_y_np_Onehot, verbose=0)\n",
        "\n",
        "        x_testNp = x_testNp.reshape(int(x_testNp.shape[0]/(img_rows)), img_rows, img_cols, 1)\n",
        "        x_testNp = (x_testNp-x_mean)/x_std\n",
        "\n",
        "        predict_x = model.predict(x_testNp)\n",
        "        predction = np.argmax(predict_x, axis=1)\n",
        "\n",
        "        print('Test loss:', score[0])\n",
        "        print('Test accuracy:', score[1])\n",
        "\n",
        "        return predction\n",
        "\n",
        "\n",
        "class LSTM_Model:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def Classification(self, x_train_all_Np, y_train_all_Np, x_testNp, y_testNp):\n",
        "        Set = _config()\n",
        "        process = _preprocess()\n",
        "        # learning_rate = 0.001\n",
        "        training_iters = Set.epoch\n",
        "        batch_size = Set.Batch_size\n",
        "        display_step = 10\n",
        "\n",
        "        n_input = Set.imgcol\n",
        "        n_step = Set.imgrow-1\n",
        "        n_hidden = 256\n",
        "        n_classes = Set.class_num\n",
        "\n",
        "        train_x_np, val_x_np = process.splitdata(x_train_all_Np, 0.8, 1)\n",
        "        train_y_np, val_y_np = process.splitdata(y_train_all_Np, 0.8, 1)\n",
        "\n",
        "        x_train_all_Np = x_train_all_Np.reshape(-1, n_step, n_input)\n",
        "        train_x_np = train_x_np.reshape(-1, n_step, n_input)\n",
        "        val_x_np = val_x_np.reshape(-1, n_step, n_input)\n",
        "\n",
        "        # train_x_np = train_x_np.astype('float32')\n",
        "        # val_x_np = val_x_np.astype('float32')\n",
        "\n",
        "        x_mean = np.mean(x_train_all_Np, axis=0)\n",
        "        x_std = np.std(x_train_all_Np, axis=0)\n",
        "\n",
        "        train_x_np = (train_x_np-x_mean)/x_std\n",
        "        val_x_np = (val_x_np-x_mean)/x_std\n",
        "\n",
        "        train_y_np_Onehot = keras.utils.to_categorical(train_y_np, n_classes)\n",
        "        val_y_np_Onehot = keras.utils.to_categorical(val_y_np, n_classes)\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(n_hidden, batch_input_shape=(\n",
        "            None, n_step, n_input), unroll=True))\n",
        "        # model.add(LSTM(n_hidden,unroll=True))\n",
        "        # model.add(LSTM(n_hidden))\n",
        "\n",
        "        # model.add(LSTM(n_hidden,batch_input_shape=(None, n_step, n_input),unroll=True))\n",
        "\n",
        "        # model.add(Bidirectional(LSTM(units=2,return_sequences=False)))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(n_classes))\n",
        "        model.add(Activation('softmax'))\n",
        "\n",
        "        adam = Adam(lr=0.001)\n",
        "        model.summary()\n",
        "        model.compile(optimizer=adam,\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        model.fit(train_x_np, train_y_np_Onehot,\n",
        "                  batch_size=batch_size,\n",
        "                  epochs=training_iters,\n",
        "                  verbose=1,\n",
        "                  validation_data=(val_x_np, val_y_np_Onehot))\n",
        "\n",
        "        scores = model.evaluate(val_x_np, val_y_np_Onehot, verbose=2)\n",
        "        print('LSTM test score:', scores[0])\n",
        "        print('LSTM test accuracy:', scores[1])\n",
        "\n",
        "        x_testNp = x_testNp.reshape(-1, n_step, n_input)\n",
        "        x_testNp = (x_testNp-x_mean)/x_std\n",
        "        predction = model.predict_classes(x_testNp)\n",
        "        print(predction)\n",
        "        return predction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emh3ngEcH4ou"
      },
      "source": [
        "主程式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRYs1oheH-wm",
        "outputId": "ceb8b099-aca0-42ea-dc6e-cda19c6cca6c"
      },
      "outputs": [
        {
          "ename": "UnboundLocalError",
          "evalue": "local variable 'ResultNp' referenced before assignment",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m     Project_Classification()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[13], line 46\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m     45\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Use GPU 0\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     \u001b[43mProject_Classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[13], line 16\u001b[0m, in \u001b[0;36mProject_Classification\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m Set \u001b[38;5;241m=\u001b[39m _config()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Read train data and test data\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m train_x, train_y, trainfilename \u001b[38;5;241m=\u001b[39m \u001b[43mtXt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReadData_TxT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrain_Path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m test_x, test_y, testfilename \u001b[38;5;241m=\u001b[39m tXt\u001b[38;5;241m.\u001b[39mReadData_TxT(Set\u001b[38;5;241m.\u001b[39mTest_Path)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=======\u001b[39m\u001b[38;5;124m'\u001b[39m, train_x\u001b[38;5;241m.\u001b[39mshape, train_y\u001b[38;5;241m.\u001b[39mshape)\n",
            "Cell \u001b[0;32mIn[2], line 80\u001b[0m, in \u001b[0;36m_file.ReadData_TxT\u001b[0;34m(self, Path)\u001b[0m\n\u001b[1;32m     78\u001b[0m PTClabelNp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([PTClabelList])\n\u001b[1;32m     79\u001b[0m PTClabelNp \u001b[38;5;241m=\u001b[39m PTClabelNp\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mResultNp\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ResultNp, PTClabelNp, namelist\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'ResultNp' referenced before assignment"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tkinter import font\n",
        "import os\n",
        "\n",
        "# Placeholder imports for _file, _config, CNN_Model, and LSTM_Model\n",
        "#from file import _file\n",
        "#from config import _config\n",
        "#from Mymodel import CNN_Model, LSTM_Model\n",
        "\n",
        "def Project_Classification():\n",
        "    tXt = _file()\n",
        "    Set = _config()\n",
        "    \n",
        "    # Read train data and test data\n",
        "    train_x, train_y, trainfilename = tXt.ReadData_TxT(Set.Train_Path)\n",
        "    test_x, test_y, testfilename = tXt.ReadData_TxT(Set.Test_Path)\n",
        "    print('=======', train_x.shape, train_y.shape)\n",
        "    \n",
        "    Real_y = list()\n",
        "    for i in testfilename:\n",
        "        _class = Set.test_y[i]\n",
        "        Real_y.append(Set.PTC_class[_class])\n",
        "        \n",
        "    CNN = CNN_Model()\n",
        "    Predict_Y = CNN.Classification(train_x, train_y, test_x, test_y)\n",
        "    \n",
        "    # Uncomment to use LSTM_Model instead\n",
        "    # LSTM = LSTM_Model()\n",
        "    # Predict_Y = LSTM.Classification(train_x, train_y, test_x, test_y)\n",
        "\n",
        "    Real_yNp = np.array(Real_y)\n",
        "    print('predict:', Predict_Y)\n",
        "    print('Real:   ', Real_yNp)\n",
        "    \n",
        "    Result = 0\n",
        "    for i in range(Real_yNp.shape[0]):\n",
        "        if Predict_Y[i] == Real_yNp[i]:\n",
        "            Result += 1\n",
        "    \n",
        "    Accuracy = (Result / Real_yNp.shape[0]) * 100\n",
        "    print('Accuracy(%):', Accuracy)\n",
        "\n",
        "def main():\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Use GPU 0\n",
        "    Project_Classification()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
