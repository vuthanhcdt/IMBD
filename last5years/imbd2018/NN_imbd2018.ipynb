{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN5lvJiPHTSx"
      },
      "source": [
        "匯入套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "--0dKXjIHaHT"
      },
      "outputs": [],
      "source": [
        "import os  \n",
        "import xlrd\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH2POeOHHchg"
      },
      "source": [
        "載入雲端硬碟"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bX7Y3ISHkAx",
        "outputId": "5ff3a607-1a45-4c65-c744-050b9645e685"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m, force_remount\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyCqqqocGxJ0",
        "outputId": "70c14d16-49f7-4e08-ead4-12f2d11d8d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20160425009_2016425_19220.xls\n",
            "20160428011_2016428_191949.xls\n",
            "20160419002_2016419_132916.xls\n",
            "20160425002_2016425_104626.xls\n",
            "20160422004_2016422_17837.xls\n",
            "20160429004_2016429_14936.xls\n",
            "20160429000_2016429_84549.xls\n",
            "20160419001_2016419_114348.xls\n",
            "20160429002_2016429_104511.xls\n",
            "20160419000_2016419_10450.xls\n",
            "20160427003_2016427_17747.xls\n",
            "20160427001_2016427_14570.xls\n",
            "20160419004_2016419_153453.xls\n",
            "20160429003_2016429_11447.xls\n",
            "20160519001_2016519_145215.xls\n",
            "20160419005_2016419_164411.xls\n",
            "20160428007_2016428_15325.xls\n",
            "20160425003_2016425_11527.xls\n",
            "20160426001_2016426_104437.xls\n",
            "20160427004_2016427_1871.xls\n",
            "20160428010_2016428_181928.xls\n",
            "20160421002_2016421_171815.xls\n",
            "20160519003_2016519_16513.xls\n",
            "20160428004_2016428_12638.xls\n",
            "20160426002_2016426_115725.xls\n",
            "20160422003_2016422_161044.xls\n",
            "20160419003_2016419_143535.xls\n",
            "20160425008_2016425_175644.xls\n",
            "20160428008_2016428_161338.xls\n",
            "20160425005_2016425_161517.xls\n",
            "20160429001_2016429_94620.xls\n",
            "20160523000_2016523_112052.xls\n",
            "20160422002_2016422_111140.xls\n",
            "20160421003_2016421_182129.xls\n",
            "20160520001_2016520_161526.xls\n",
            "20160519002_2016519_155127.xls\n",
            "20160520000_2016520_105518.xls\n",
            "20160427002_2016427_16045.xls\n",
            "20160425001_2016425_94440.xls\n",
            "20160422001_2016422_95822.xls\n",
            "20160523001_2016523_132720.xls\n",
            "20160428002_2016428_10314.xls\n",
            "20160523002_2016523_142635.xls\n",
            "20160428003_2016428_11622.xls\n",
            "20160428001_2016428_8419.xls\n",
            "20160426000_2016426_93632.xls\n",
            "20160428005_2016428_131728.xls\n",
            "20160426005_2016426_18652.xls\n",
            "20160425004_2016425_131231.xls\n",
            "20160426004_2016426_165510.xls\n",
            "[0.814]\n",
            "torch.Size([40, 7500])\n",
            "torch.Size([40, 1])\n",
            "torch.Size([10, 7500])\n",
            "torch.Size([10, 1])\n",
            "n_feature= 7500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3724/3811817865.py:125: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  error.append(float(num))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  100 | Train Loss: 0.04269251227378845 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  200 | Train Loss: 0.04269251227378845 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  300 | Train Loss: 0.04269251227378845 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  400 | Train Loss: 0.04269251227378845 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  500 | Train Loss: 0.04269251227378845 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  600 | Train Loss: 0.04269251227378845 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  700 | Train Loss: 0.04269251227378845 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  800 | Train Loss: 0.04269251227378845 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  900 | Train Loss: 0.04269251227378845 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "Epoch:  1000 | Train Loss: 0.04269251227378845 | Acc: 27.500000000000004 %\n",
            "==========================================================\n",
            "END\n",
            "0.073058315\n",
            "ans [np.float32(0.3246), np.float32(0.3477), np.float32(0.4189), np.float32(0.4251), np.float32(0.3974), np.float32(0.4737), np.float32(0.1771), np.float32(0.306), np.float32(0.3311), np.float32(0.2574)]\n",
            "test [np.float32(0.60307765), np.float32(0.6030773), np.float32(0.6030776), np.float32(0.60307753), np.float32(0.60307765), np.float32(0.60307735), np.float32(0.6030774), np.float32(0.6030777), np.float32(0.60307723), np.float32(0.60307765)]\n",
            "error [0.8579, 0.7345, 0.4397, 0.4187, 0.5176, 0.2731, 2.4053, 0.9708, 0.8214, 1.343]\n",
            "0.0 %\n",
            "===========================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3724/3811817865.py:155: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  error.append(round(float(num),4))\n"
          ]
        }
      ],
      "source": [
        "# # test_path = 'test_10/'\n",
        "# test_path = '/content/drive/My Drive/Colab Notebooks/imbd2018/test_10/'\n",
        "# # train_path = 'train_40/'\n",
        "# train_path = '/content/drive/My Drive/Colab Notebooks/imbd2018/train_40/'\n",
        "\n",
        "test_path = './test_10/'\n",
        "train_path = './train_40/'\n",
        "\n",
        "data_Spindle_X = []\n",
        "data_Spindle_Y = []\n",
        "data_Workbench_X = []\n",
        "data_Workbench_Y = []\n",
        "data_label = []\n",
        "\n",
        "test_Spindle_X = []\n",
        "test_Spindle_Y = []\n",
        "test_Workbench_X = []\n",
        "test_Workbench_Y = []\n",
        "test_label = []\n",
        "         \n",
        "def getData(file_path):\n",
        "        \n",
        "        workbook = xlrd.open_workbook(file_path)\n",
        "        sheet = workbook.sheets()[0]\n",
        "\n",
        "        sheet_data = {\n",
        "                'Spindle_X':[],\n",
        "                'Spindle_Y':[],\n",
        "                'Workbench_X':[], \n",
        "                'Workbench_Y':[]\n",
        "        }\n",
        "        \n",
        "        for i in range(7500):\n",
        "                sheet_data['Spindle_X'].append(sheet.cell(i,0).value)\n",
        "                sheet_data['Spindle_Y'].append(sheet.cell(i,1).value)\n",
        "                sheet_data['Workbench_X'].append(sheet.cell(i,2).value)\n",
        "                sheet_data['Workbench_Y'].append(sheet.cell(i,3).value)\n",
        "\t\n",
        "\n",
        "        if 'test' in file_path:\n",
        "          test_Spindle_X.append(sheet_data['Spindle_X'])\n",
        "          test_Spindle_Y.append(sheet_data['Spindle_Y'])\n",
        "          test_Workbench_X.append(sheet_data['Workbench_X'])\n",
        "          test_Workbench_Y.append(sheet_data['Workbench_Y'])\n",
        "          test_label.append([float(sheet.cell(7500,0).value[3:])])\n",
        "        else:\n",
        "          data_Spindle_X.append(sheet_data['Spindle_X'])\n",
        "          data_Spindle_Y.append(sheet_data['Spindle_Y'])\n",
        "          data_Workbench_X.append(sheet_data['Workbench_X'])\n",
        "          data_Workbench_Y.append(sheet_data['Workbench_Y'])\n",
        "          data_label.append([float(sheet.cell(7500,0).value[3:])])\n",
        "\n",
        "for file_name in os.listdir(test_path):\n",
        "        print(file_name)\n",
        "        getData(test_path+file_name)\n",
        "\n",
        "for file_name in os.listdir(train_path):\n",
        "        print(file_name)\n",
        "        getData(train_path+file_name)\n",
        "\n",
        "#RNN2\n",
        "\n",
        "trainX = torch.tensor(data_Spindle_X)\n",
        "trainY = torch.tensor(data_label)\n",
        "\n",
        "print(data_label[0])\n",
        "print(trainX.size())\n",
        "print(trainY.size())\n",
        "\n",
        "testX = torch.tensor(test_Spindle_X)\n",
        "testY = torch.tensor(test_label)\n",
        "\n",
        "print(testX.size())\n",
        "print(testY.size())\n",
        "\n",
        "\n",
        "# NN3------------------------------------------------------------\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, n_feature, n_hidden, n_output):\n",
        "        super(Net, self).__init__()\n",
        "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
        "        self.hidden_1 = torch.nn.Linear(n_hidden, n_hidden)   # hidden layer\n",
        "        self.hidden_2 = torch.nn.Linear(n_hidden, n_hidden)   # hidden layer\n",
        "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
        "        \n",
        "        x = F.relu(self.hidden_1(x))\n",
        "        x = F.relu(self.hidden_2(x))\n",
        "        \n",
        "        x = self.predict(x)             # linear output\n",
        "        return x\n",
        "\n",
        "net = Net(n_feature=len(trainX[0]), n_hidden=256, n_output=1)     # define the network\n",
        "print('n_feature=',len(trainX[0]))\n",
        "\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.045)\n",
        "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
        "\n",
        "all_error = []\n",
        "\n",
        "for t in range(1,1001):\n",
        "    prediction = net(trainX)     # input x and predict based on x\n",
        "    #print 'prediction',prediction,'trainY',trainY\n",
        "    loss = loss_func(prediction, trainY)     # must be (1. nn output, 2. target)\n",
        "    #print loss\n",
        "    optimizer.zero_grad()   # clear gradients for next train\n",
        "    loss.backward()         # backpropagation, compute gradients\n",
        "    optimizer.step()        # apply gradients\n",
        "\n",
        "    if t % 100 == 0:\n",
        "        \n",
        "        k = prediction.data.numpy()\n",
        "        ans = trainY.numpy()\n",
        "        real = []\n",
        "        right = []\n",
        "        error = []\n",
        "        count = 0.0\n",
        "        for i in range(len(ans)):\n",
        "            num = abs(ans[i][0] - k[i][0]) / ans[i]\n",
        "            real.append(ans[i][0])\n",
        "            right.append(k[i][0])\n",
        "            error.append(float(num))\n",
        "            if num < 0.1:\n",
        "                count = count + 1.0\n",
        "        print('Epoch: ',t,'| Train Loss:',float(loss.data.numpy()),'| Acc:',(count / len(ans)) * 100,'%')\n",
        "        all_error.append(error)\n",
        "        print('==========================================================')\n",
        "\n",
        "print ('END')\n",
        "#torch.save(net,'/content/drive/My Drive/IMDB/CNC_tcim_20180715.pkl')\n",
        "torch.save(net,'CNC_tcim_20180715.pkl')\n",
        "\n",
        "\n",
        "# NN4------------------------------------------------------------\n",
        "#net = torch.load('/content/drive/My Drive/IMDB/CNC_tcim_20180715.pkl')\n",
        "net = torch.load('CNC_tcim_20180715.pkl')\n",
        "\n",
        "prediction = net(testX)     # input x and predict based on x\n",
        "\n",
        "loss = loss_func(prediction, testY)     # must be (1. nn output, 2. target)\n",
        "print(loss.data.numpy())\n",
        "k = prediction.data.numpy()\n",
        "ans = testY.numpy()\n",
        "real = []\n",
        "right = []\n",
        "error = []\n",
        "count = 0.0\n",
        "for i in range(len(ans)):\n",
        "    num = abs(ans[i][0] - k[i][0]) / ans[i]\n",
        "    real.append(ans[i][0])\n",
        "    right.append(round(k[i][0],8))\n",
        "    error.append(round(float(num),4))\n",
        "    if num < 0.1:\n",
        "        count = count + 1.0\n",
        "print('ans',real)\n",
        "print('test',right)\n",
        "print('error',error)\n",
        "print((count / len(ans)) * 100,'%')\n",
        "print('===========================')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
